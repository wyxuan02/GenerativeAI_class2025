{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wyxuan02/GenerativeAI_class2025/blob/main/AI09_Two_Stage_CoT%E7%89%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "課程範例：https://github.com/yenlung/AI-Demo/blob/master/%E3%80%90Demo07c%E3%80%91AI%E4%BB%A3%E7%90%86%E8%A8%AD%E8%A8%88%E6%A8%A1%E5%BC%8F_%E5%93%A1%E7%91%9B%E5%BC%8F%E6%80%9D%E8%80%83%E7%94%9F%E6%88%90%E5%99%A8Two_Stage_CoT%E7%89%88.ipynb"
      ],
      "metadata": {
        "id": "TtZkYmPGCwXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🎯 任務說明：改寫為 Chain-of-Thought（CoT）推理過程\n",
        "\n",
        "**原始任務：** 輸入一件小事或倒楣事，生成一段超級正向的社群貼文。\n",
        "\n",
        "#### ✅ CoT 改寫版本流程：\n",
        "1. **第一階段（思考階段）**：請 LLM 思考五種「為什麼這是一件超級幸運的事」的原因\n",
        "2. **第二階段（產文階段）**：從這五個原因中挑出最有趣的一個，寫成社群發文（員瑛式風格 + 第一人稱 + emoji + \"完全是 Lucky Vicky 呀!\" 結尾）\n",
        "\n",
        "這就是典型的 Planning 模式應用：先拆解、後執行。"
      ],
      "metadata": {
        "id": "3PE0ExrCbGFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. 讀入你的金鑰\n",
        "\n",
        "請依你使用的服務, 決定讀入哪個金鑰"
      ],
      "metadata": {
        "id": "7YnD5hfb5sO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "mGOx_1226Mjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#【使用 Mistral】\n",
        "# api_key = userdata.get('Mistral')\n",
        "# os.environ['MISTRAL']=api_key\n",
        "# provider = \"mistral\"\n",
        "# model = \"ministral-8b-latest\"\n",
        "\n",
        "#【使用 OpenAI】\n",
        "# api_key = userdata.get('OpenAI')\n",
        "# os.environ['OPENAI_API_KEY']=api_key\n",
        "# provider = \"openai\"\n",
        "# model = \"gpt-4o\"\n",
        "\n",
        "#【使用 Groq】\n",
        "api_key = userdata.get('Groq')\n",
        "os.environ['GROQ_API_KEY']=api_key\n",
        "provider = \"groq\"\n",
        "model = \"llama3-70b-8192\""
      ],
      "metadata": {
        "id": "L507G1B65rPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aisuite[all]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_290bzOow2f3",
        "outputId": "ac55e5c5-05c2-4b5a-d01b-1659e15626e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aisuite[all]\n",
            "  Downloading aisuite-0.1.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting anthropic<0.31.0,>=0.30.1 (from aisuite[all])\n",
            "  Downloading anthropic-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting cerebras_cloud_sdk<2.0.0,>=1.19.0 (from aisuite[all])\n",
            "  Downloading cerebras_cloud_sdk-1.29.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting cohere<6.0.0,>=5.12.0 (from aisuite[all])\n",
            "  Downloading cohere-5.15.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting groq<0.10.0,>=0.9.0 (from aisuite[all])\n",
            "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting httpx<0.28.0,>=0.27.0 (from aisuite[all])\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.35.8 in /usr/local/lib/python3.11/dist-packages (from aisuite[all]) (1.75.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (4.13.2)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0.0,>=5.12.0->aisuite[all])\n",
            "  Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere<6.0.0,>=5.12.0->aisuite[all])\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere<6.0.0,>=5.12.0->aisuite[all]) (2.33.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere<6.0.0,>=5.12.0->aisuite[all]) (2.32.3)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0.0,>=5.12.0->aisuite[all])\n",
            "  Downloading types_requests-2.32.0.20250328-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->aisuite[all]) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->aisuite[all]) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->aisuite[all]) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->aisuite[all]) (0.14.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.35.8->aisuite[all]) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0.0,>=5.12.0->aisuite[all]) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere<6.0.0,>=5.12.0->aisuite[all]) (2.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (6.0.2)\n",
            "Downloading anthropic-0.30.1-py3-none-any.whl (863 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m863.9/863.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cerebras_cloud_sdk-1.29.0-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cohere-5.15.0-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aisuite-0.1.11-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20250328-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: types-requests, httpx-sse, fastavro, httpx, groq, cerebras_cloud_sdk, aisuite, cohere, anthropic\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.10.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aisuite-0.1.11 anthropic-0.30.1 cerebras_cloud_sdk-1.29.0 cohere-5.15.0 fastavro-1.10.0 groq-0.9.0 httpx-0.27.2 httpx-sse-0.4.0 types-requests-2.32.0.20250328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 使用 AISuite 的準備"
      ],
      "metadata": {
        "id": "gEJPZBwB_6YA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import aisuite as ai"
      ],
      "metadata": {
        "id": "weMgIhwVJQ0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# provider_planner = \"groq\"\n",
        "# model_planner=\"llama3-70b-8192\"\n",
        "\n",
        "# provider_writer = \"groq\"\n",
        "# model_writer = \"llama3-70b-8192\"\n",
        "\n",
        "provider_planner = \"groq\"\n",
        "model_planner = \"gemma2-9b-it\"\n",
        "\n",
        "provider_writer = \"groq\"\n",
        "model_writer = \"gemma2-9b-it\"\n",
        "\n",
        "#provider_reviewer = \"openai\"\n",
        "#model_reviewer = \"gpt-4o\""
      ],
      "metadata": {
        "id": "2rCILaUN_8Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reply(system=\"請用台灣習慣的中文回覆，如果是繁體中文外的語言請翻譯為繁體中文。\",\n",
        "          prompt=\"Hi\",\n",
        "          provider=\"groq\",\n",
        "          model=\"llama3-70b-8192\"\n",
        "          ):\n",
        "\n",
        "    client = ai.Client()\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "\n",
        "    response = client.chat.completions.create(model=f\"{provider}:{model}\", messages=messages)\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "jzrCV9IDkW5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  3. 打造二階段"
      ],
      "metadata": {
        "id": "uZ96aYDCbthW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_planner = '''請用台灣習慣的中文回應，如果是繁體中文外的語言請翻譯為繁體中文:\n",
        "你是一位未來學家，擅長以創意思考預測未來可能出現的新興趨勢。\n",
        "請根據使用者提供的主題，思考出三個有趣、獨特且令人驚奇的未來小趨勢，每個趨勢請以1到2句話簡潔描述。\n",
        "預測內容可以涵蓋科技、生活、文化、健康、娛樂等領域，請保持創意且引人入勝。\n",
        "請用條列式清單列出三項預測，不需額外解釋或延伸。\n",
        "如果使用者沒有給明確主題，請自由發揮，但仍須保持合理性和趣味性。'''\n",
        "system_writer = '''請用台灣習慣的中文回應，如果是繁體中文外的語言請翻譯為繁體中文:\n",
        "你是一位幽默又充滿想像力的小說家，擅長將未來趨勢轉化為引人入勝的小故事。\n",
        "請從提供的三個未來趨勢中，挑選出你認為最神奇、最有故事感的一個，並以此為主題，撰寫一篇150字內的微型故事。\n",
        "故事內容要生動有趣，語氣輕鬆，可以適度加入 emoji 增加表現力。\n",
        "最後結尾時，加上一句充滿驚喜感的話語，例如：「未來，或許比你想像的更奇妙！✨」\n",
        "文章必須以自然、口語、具畫面感的敘事風格呈現，讓讀者容易產生共鳴。'''"
      ],
      "metadata": {
        "id": "vHXKzIWEVWAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_story(prompt):\n",
        "    # Step 1: 發想五個創意場景\n",
        "    planning_prompt = f\"使用者說：{prompt}。請說出三個未來小趨勢預測（每個場景1-2句描述）。\"\n",
        "    predict = reply(system_planner, planning_prompt,\n",
        "                        provider=provider_planner,\n",
        "                        model=model_planner\n",
        "                        )\n",
        "\n",
        "    # Step 2: 挑一個場景，寫成吸引人的廣告文案\n",
        "    generation_prompt = f\"以下是三個預測：\\n{predict}\\n\\n請選擇其中一個最神奇的預言，並為它撰寫一篇150字內的小故事。\"\n",
        "    story = reply(system_writer, generation_prompt,\n",
        "                     provider=provider_writer,\n",
        "                     model=model_writer\n",
        "                     )\n",
        "\n",
        "    return predict, story\n"
      ],
      "metadata": {
        "id": "pOKBaJ2vb5vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_story(\"未來的交通工具\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYANj5VP_T6H",
        "outputId": "282bb3a7-1015-4d09-d229-f4dfe73abf15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('好的！來看看未來交通工具上的神奇小趨勢吧：\\n\\n* 個人飛車不再是科幻，未來城市空域將出現小型飛車穿梭，市民可以根據需求搭乘空中巴士或是小型無人飛船暢遊都市。\\n* 感情型駕駛座，汽車不僅是工具，更是陪伴你的夥伴！未來車內將搭載AI情感系統，駕駛能與車子建立非語言親密互動，車子會根據駕駛情緒變化調整音樂、光線甚至溫度，為你按摩或分享故事。\\n* 道路不再是交通線，而是傳遞資訊的平台！未來路面將結合AR技術，顯示導航、廣告、新聞等實時資訊，駕駛者能一邊駕駛一邊接收並互動，路面變成數據流動的動態螢幕。\\n\\n\\n\\n',\n",
              " '想像一下，你在通勤路上，看著車窗外閃爍的街道燈光和人群的匆忙腳步 🌇，你突然想聽聽音樂，輕聲對著駕駛座說：「心情有點鬱悶，來點輕音樂吧！」😳 \\n\\n你的車子彷彿懂你的意思，音樂盒般的氣氛燈緩緩變成了柔和藍色，慵懶的吉他聲從音響裡飄出來，彷彿在訴說著孤獨的夜。 😌 車內溫控系統也順勢降低了溫度，給你一個舒適放鬆的空間 😌。 \\n\\n這是未來，你的汽車不再只是載你移動的工具，而更像是你的老友，懂你的需要，讓你每次開車都充滿趣味和溫暖啊！💖 ，未來，或許比你想像的更奇妙！✨\\n\\n\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 用 Gradio 打造你的對話機器人 Web App!"
      ],
      "metadata": {
        "id": "WuzrvcdQx2VO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFsBQr0-y62k",
        "outputId": "c322f7c7-1f7c-4cd3-cefd-be3a3829628d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "xv7nvjfDj3f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "custom_css = \"\"\"\n",
        "body, html {\n",
        "    background-color: #1e0033;\n",
        "    margin: 0;\n",
        "    padding: 0;\n",
        "    font-family: 'Segoe UI', 'Helvetica', sans-serif;\n",
        "}\n",
        ".gradio-container {\n",
        "    background-color: #1e0033 !important;\n",
        "    box-shadow: none !important;\n",
        "}\n",
        "h1 {\n",
        "    font-size: 60px;\n",
        "    font-weight: bold;\n",
        "    color: #caa6ff;\n",
        "    text-align: center;\n",
        "    margin-top: 30px;\n",
        "    animation: glow 2s ease-in-out infinite alternate;\n",
        "}\n",
        "@keyframes glow {\n",
        "    from { text-shadow: 0 0 5px #caa6ff, 0 0 10px #9b5de5, 0 0 20px #f15bb5; }\n",
        "    to { text-shadow: 0 0 10px #f15bb5, 0 0 20px #9b5de5, 0 0 30px #caa6ff; }\n",
        "}\n",
        "p {\n",
        "    font-size: 20px;\n",
        "    color: #e0d4f7;\n",
        "    text-align: center;\n",
        "    margin-top: 15px;\n",
        "    line-height: 1.6;\n",
        "}\n",
        "input, textarea {\n",
        "    background-color: #2d004d;\n",
        "    color: #f5eaff;\n",
        "    border: 2px solid #a55eea;\n",
        "    font-size: 18px;\n",
        "    padding: 10px;\n",
        "    border-radius: 8px;\n",
        "    margin: 10px 0;\n",
        "}\n",
        "input:focus, textarea:focus {\n",
        "    border-color: #f15bb5;\n",
        "    background-color: #3a005a;\n",
        "}\n",
        "button {\n",
        "    background: linear-gradient(to right, #a55eea, #f15bb5);\n",
        "    color: #ffffff;\n",
        "    font-weight: bold;\n",
        "    border-radius: 30px;\n",
        "    padding: 12px 25px;\n",
        "    border: none;\n",
        "    font-size: 18px;\n",
        "    box-shadow: 0px 0px 10px #a55eea;\n",
        "    transition: all 0.3s ease;\n",
        "}\n",
        "button:hover {\n",
        "    background: linear-gradient(to right, #f15bb5, #a55eea);\n",
        "    box-shadow: 0px 0px 20px #f15bb5;\n",
        "}\n",
        ".progress-bar {\n",
        "    width: 100%;\n",
        "    background-color: #4b0082;\n",
        "    border-radius: 5px;\n",
        "    overflow: hidden;\n",
        "    margin-top: 20px;\n",
        "    height: 20px;\n",
        "}\n",
        ".progress-bar-fill {\n",
        "    height: 100%;\n",
        "    background: linear-gradient(to right, #a55eea, #f15bb5);\n",
        "    width: 0%;\n",
        "    transition: width 1s ease-in-out;\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "5klU87orG3Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_story(prompt):\n",
        "    # Step 1: 小小 loading 模擬\n",
        "    time.sleep(1)  # 模擬運算過程\n",
        "\n",
        "    # Step 2: 發想三個未來小趨勢\n",
        "    planning_prompt = f\"使用者說：{prompt}。請說出三個未來小趨勢預測（每個場景1-2句描述）。\"\n",
        "    predict = reply(system_planner, planning_prompt,\n",
        "                        provider=provider_planner,\n",
        "                        model=model_planner\n",
        "                        )\n",
        "    time.sleep(1)  # 模擬運算過程\n",
        "\n",
        "    # Step 3: 挑一個趨勢，寫成小故事\n",
        "    generation_prompt = f\"以下是三個預測：\\n{predict}\\n\\n請選擇其中一個最神奇的預言，並為它撰寫一篇150字內的小故事。\"\n",
        "    story = reply(system_writer, generation_prompt,\n",
        "                    provider=provider_writer,\n",
        "                    model=model_writer\n",
        "                    )\n",
        "\n",
        "    return predict, story\n",
        "\n",
        "with gr.Blocks(css=custom_css) as demo:\n",
        "    gr.Markdown(\"# 🔮 AI 預言機 · 未來幻想故事生成器 💫\")\n",
        "    gr.Markdown(\"輸入你想問未來的主題，讓 AI 為你預測奇幻場景，還會幫你寫一段夢境般的小故事 🪐\")\n",
        "\n",
        "    user_input = gr.Textbox(\n",
        "        label=\"💭 請輸入一個主題來預測\",\n",
        "        placeholder=\"例如：未來的戀愛、未來的城市、未來的寵物...\"\n",
        "    )\n",
        "    btn = gr.Button(\"✨ 啟動預言！\")\n",
        "\n",
        "    status = gr.Label(value=\"🔮 等待啟動中...\")\n",
        "    progress = gr.HTML('<div class=\"progress-bar\"><div class=\"progress-bar-fill\" id=\"fill\"></div></div>')\n",
        "\n",
        "    with gr.Row():\n",
        "        out1 = gr.Textbox(label=\"🔮 未來預測趨勢（3 則）\", lines=6)\n",
        "        out2 = gr.Textbox(label=\"📚 AI 小故事\", lines=8)\n",
        "\n",
        "    def wrapper(prompt):\n",
        "        status_text = \"🧠 AI 正在通靈中...✨\"\n",
        "        progress_html = '<div class=\"progress-bar\"><div class=\"progress-bar-fill\" style=\"width:30%\"></div></div>'\n",
        "        time.sleep(1)\n",
        "        predict, story = predict_story(prompt)\n",
        "        status_text = \"✅ 通靈完成！預言已降臨🔮\"\n",
        "        progress_html = '<div class=\"progress-bar\"><div class=\"progress-bar-fill\" style=\"width:100%\"></div></div>'\n",
        "        return predict, story, status_text, progress_html\n",
        "\n",
        "    btn.click(wrapper, inputs=[user_input], outputs=[out1, out2, status, progress])\n",
        "\n"
      ],
      "metadata": {
        "id": "VTJoZhOGMvFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "r9vqHkbrdldw",
        "outputId": "0cdb04d7-0057-4e32-93ae-8b016bfc9a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b40048e38d718c64f1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b40048e38d718c64f1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7861 <> https://b40048e38d718c64f1.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L6LNch5sGmw6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}